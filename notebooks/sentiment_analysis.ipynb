{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "What is the overall sentiment of tweets pertaining to covid? How does that change according to province/over time? Are tweets talking about different topics specific pain points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameron/.local/share/virtualenvs/COVID-Child-Care-Twitter-OW82RhPk/lib/python3.7/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from utils import DTYPE, PARSE_DATES, PROV_CONSOLIDATION, CONSOLIDATED_PROVINCES, CONVERTERS, ANCHOR_NAMES, PROVINCE_COLOR_MAP\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# prov_map = lambda x : x if x not in PROV_CONSOLIDATION else PROV_CONSOLIDATION[x]\n",
    "\n",
    "# total_df = pd.read_csv(\"../data/processed_data/total_tweet_dataset.csv\",header=0,dtype=DTYPE,converters=CONVERTERS,parse_dates=PARSE_DATES)\n",
    "# total_df = total_df.set_index(\"id\").sort_values(\"created_at\")[~total_df.index.duplicated()]\n",
    "\n",
    "# total_df[\"created_at\"] = total_df[\"created_at\"].dt.to_period(\"D\").dt.to_timestamp('s')\n",
    "# total_df[\"province\"] = total_df[\"province\"].apply(prov_map)\n",
    "# total_df = total_df[total_df.clean_text.notnull()]\n",
    "# total_df[\"province\"] = total_df[\"province\"].apply(prov_map)\n",
    "# total_df = total_df[total_df[\"province\"].isin(CONSOLIDATED_PROVINCES)]\n",
    "# print(len(total_df))\n",
    "# total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaleido.scopes.plotly import PlotlyScope\n",
    "scope = PlotlyScope()\n",
    "vis_args = {\n",
    "    \"template\": \"simple_white\",\n",
    "    \"font\":{\"size\": 23},\n",
    "    \"width\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "tb = Blobber()\n",
    "\n",
    "engine = \"Vader\"\n",
    "sentiment_engines = {\n",
    "    \"NaiveBayes\": lambda x : tb(x).polarity,\n",
    "    \"Vader\": lambda x : analyzer.polarity_scores(x)['compound']\n",
    "}\n",
    "\n",
    "total_df[\"polarity\"] = total_df[[\"clean_text\"]].progress_apply(lambda x: sentiment_engines[engine](x[\"clean_text\"]),axis=1)\n",
    "total_df[\"polarity_bucket\"] = total_df[\"polarity\"].map(lambda x : \"positive\" if x >= 0.1 else \"negative\" if x <= -0.1 else \"NA\")\n",
    "total_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75780b1246042f594a00e68af49842f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=402217.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57121bc1e89c48df8bd0924fc98a62d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=402217.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sent = pd.DataFrame()\n",
    "sent[\"tb\"] = total_df[[\"clean_text\"]].progress_apply(lambda x: sentiment_engines[\"NaiveBayes\"](x[\"clean_text\"]),axis=1)\n",
    "sent[\"vader\"] = total_df[[\"clean_text\"]].progress_apply(lambda x: sentiment_engines[\"Vader\"](x[\"clean_text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.235</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.235</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.235e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Oct 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:15</td>     <th>  Log-Likelihood:    </th> <td>-2.3621e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>402217</td>      <th>  AIC:               </th>  <td>4.724e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>402215</td>      <th>  BIC:               </th>  <td>4.724e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.1051</td> <td>    0.001</td> <td>  141.471</td> <td> 0.000</td> <td>    0.104</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.0064</td> <td>    0.003</td> <td>  351.366</td> <td> 0.000</td> <td>    1.001</td> <td>    1.012</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15123.551</td> <th>  Durbin-Watson:     </th> <td>   1.514</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>16003.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.468</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.718</td>   <th>  Cond. No.          </th> <td>    4.22</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.235\n",
       "Model:                            OLS   Adj. R-squared:                  0.235\n",
       "Method:                 Least Squares   F-statistic:                 1.235e+05\n",
       "Date:                Wed, 28 Oct 2020   Prob (F-statistic):               0.00\n",
       "Time:                        10:22:15   Log-Likelihood:            -2.3621e+05\n",
       "No. Observations:              402217   AIC:                         4.724e+05\n",
       "Df Residuals:                  402215   BIC:                         4.724e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.1051      0.001    141.471      0.000       0.104       0.107\n",
       "x1             1.0064      0.003    351.366      0.000       1.001       1.012\n",
       "==============================================================================\n",
       "Omnibus:                    15123.551   Durbin-Watson:                   1.514\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16003.196\n",
       "Skew:                          -0.468   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.718   Cond. No.                         4.22\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    \"x\": \"tb\",\n",
    "    \"y\": \"vader\",\n",
    "    \"template\": \"simple_white\",\n",
    "    \"labels\": {\"tb\": \"Text Blob (Naive Bayes)\", \"vader\": \"Vader Sentiment Analyzer\"},\n",
    "    \"opacity\": 0.05,\n",
    "    \"trendline\": \"ols\",\n",
    "    \"trendline_color_override\": \"red\"\n",
    "}\n",
    "fig = px.scatter(sent, **args)\n",
    "px.get_trendline_results(fig).px_fit_results.iloc[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_layout(**vis_args)\n",
    "\n",
    "fp = f\"../visualizations/sentiment_analysis/vader_tb-comp\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[\"residual\"] = sent[\"tb\"]-sent[\"vader\"]\n",
    "args = {\n",
    "    \"x\": \"residual\",\n",
    "    \"labels\": {\"residual\": \"Residual\",\"count\": \"Frequency\"},\n",
    "    \"nbins\":20\n",
    "}\n",
    "fig = px.histogram(sent, **args)\n",
    "fig.update_layout(**vis_args)\n",
    "fp = f\"../visualizations/sentiment_analysis/vader_tb-residual_hist\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = total_df[[\"polarity_bucket\",\"source\"]].groupby(\"polarity_bucket\").count().rename({\"source\":\"count\"},axis=1).reset_index()\n",
    "fig = px.pie(c, values='count', names='polarity_bucket')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_date = total_df.groupby([\"created_at\",\"polarity_bucket\"]).count()[[\"source\"]].rename({\"source\":\"count\"},axis=1).reset_index()\n",
    "by_date[\"percentage\"] = by_date['count'] / by_date.groupby('created_at')['count'].transform('sum')\n",
    "args = {\n",
    "    \"x\": \"created_at\",\n",
    "    \"y\": \"percentage\",\n",
    "    \"color\": \"polarity_bucket\",\n",
    "    \"template\": \"simple_white\",\n",
    "    \"labels\": {\"percentage\": \"Proportion of Tweets\", \"created_at\": \"Date\", \"polarity_bucket\": \"Sentiment\"}\n",
    "}\n",
    "fig = px.area(by_date,**args)\n",
    "fig.update_yaxes(dict(tickformat=',.0%'))\n",
    "fig.update_layout(**vis_args)\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-sentiment_proportion\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "by_date = total_df.groupby([pd.Grouper(key='created_at', freq='W-MON'),\"polarity_bucket\"]).count()[[\"source\"]].rename({\"source\":\"count\"},axis=1).reset_index()\n",
    "by_date[\"percentage\"] = by_date['count'] / by_date.groupby(pd.Grouper(key='created_at', freq='W-MON'))['count'].transform('sum')\n",
    "args = {\n",
    "    \"x\": \"created_at\",\n",
    "    \"y\": \"percentage\",\n",
    "    \"color\": \"polarity_bucket\",\n",
    "    \"template\": \"simple_white\",\n",
    "    \"labels\": {\"percentage\": \"Proportion of Tweets\", \"created_at\": \"Date\", \"polarity_bucket\": \"Sentiment\"}\n",
    "}\n",
    "fig = px.area(by_date,**args)\n",
    "fig.update_yaxes(dict(tickformat=',.0%'))\n",
    "fig.update_layout(**vis_args)\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-sentiment_proportion\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def r2(x,y):\n",
    "    x = x.to_numpy(dtype=float).reshape(-1,1)\n",
    "    y = y.to_numpy(dtype=float)\n",
    "    # Fit a linear regression to our model and its results\n",
    "    reg = LinearRegression().fit(x, y) \n",
    "    return reg.score(x, y)\n",
    "\n",
    "for bucket in by_date[\"polarity_bucket\"].unique():\n",
    "    iso = by_date[by_date[\"polarity_bucket\"] == bucket]\n",
    "    r = r2(iso.index,iso[\"count\"])\n",
    "    print(f\"{bucket} r^2={r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(total_df.sort_values(\"polarity\",ascending=False).head()[\"original_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment by Topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_avg = total_df.groupby([pd.Grouper(key='created_at', freq='W-MON'),\"cluster_name\"])[[\"polarity\"]].mean().rename({\"polarity\":\"polarity_mean\"},axis=1).reset_index()\n",
    "args = {\n",
    "    \"x\": \"created_at\",\n",
    "    \"y\": \"polarity_mean\",\n",
    "    \"color\": \"cluster_name\",\n",
    "    \"template\": \"simple_white\",\n",
    "    \"labels\": {\"polarity_mean\": \"Average Sentiment\", \"created_at\": \"Date\", \"cluster_name\": \"Topic\"},\n",
    "    \"line_shape\": \"spline\"\n",
    "}\n",
    "fig = px.line(sentiment_avg,**args)\n",
    "fig.update_layout(**vis_args)\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-topic_timeseries\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sent_corr = sentiment_avg.pivot(index=\"created_at\",values=\"polarity_mean\",columns=\"cluster_name\").corr()\n",
    "corr_matrix = topic_sent_corr.to_numpy()\n",
    "labels = topic_sent_corr.columns\n",
    "for i in range(len(corr_matrix)):\n",
    "    corr_matrix[i,i] = None\n",
    "    \n",
    "\n",
    "\n",
    "data = go.Heatmap(z=corr_matrix,y=labels,x=labels)\n",
    "fig = go.Figure(data=data,layout=vis_args)\n",
    "\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-topic_sentiment_correlation\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for prov in CONSOLIDATED_PROVINCES:\n",
    "    iso = total_df[total_df[\"province\"]==prov]\n",
    "    fig.add_trace(go.Box(\n",
    "        y=iso[\"polarity\"],\n",
    "        x=iso[\"cluster_name\"],\n",
    "#         boxpoints=False,\n",
    "        name=prov,\n",
    "        marker_color=PROVINCE_COLOR_MAP[prov]\n",
    "    ))\n",
    "    \n",
    "fig.add_trace(go.Box(\n",
    "        y=total_df[\"polarity\"],\n",
    "        x=total_df[\"cluster_name\"],\n",
    "#         boxpoints=False,\n",
    "        name='Total',\n",
    "        marker_color=PROVINCE_COLOR_MAP['Total']\n",
    "    ))\n",
    "\n",
    "args = {\n",
    "    \"font\":{\"size\": 23},\n",
    "    \"height\": 700,\n",
    "    \"width\": 2000,    \n",
    "    \"template\":\"simple_white\",\n",
    "    \"yaxis\":{\"showline\": False},\n",
    "    \"boxmode\":'group' # group together boxes of the different traces for each value of x\n",
    "\n",
    "}\n",
    "fig.update_layout(**args)\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-box_plot-sentiment_by_province\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment by Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_avg = total_df.groupby([\"province\",\"cluster_name\"])[[\"polarity\"]].mean().rename({\"polarity\":\"polarity_mean\"},axis=1).reset_index()\n",
    "data = []\n",
    "for name in ANCHOR_NAMES+[\"Overflow\"]:\n",
    "    iso = sentiment_avg[sentiment_avg[\"cluster_name\"]==name]\n",
    "    data.append(go.Bar(name=name, x=iso[\"province\"], y=iso[\"polarity_mean\"]))\n",
    "fig = go.Figure(data=data)\n",
    "args = {\n",
    "    \"font\":{\"size\": 23},\n",
    "    \"height\": 700,\n",
    "    \"template\":\"simple_white\",\n",
    "    \"yaxis\":{\"showline\": False},\n",
    "    \"xaxis\":{\"showline\": False},\n",
    "    \"boxmode\":'group' # group together boxes of the different traces for each value of x\n",
    "\n",
    "}\n",
    "fig.update_layout(**{**args,**vis_args})\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-sentiment_by_province\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_avg = total_df.groupby([pd.Grouper(key='created_at', freq='W-MON'),\"province\"])[[\"polarity\"]].mean().rename({\"polarity\":\"polarity_mean\"},axis=1).reset_index()\n",
    "args = {\n",
    "    \"x\": \"created_at\",\n",
    "    \"y\": \"polarity_mean\",\n",
    "    \"color\": \"province\",\n",
    "    \"template\": \"simple_white\",\n",
    "    \"labels\": {\"polarity_mean\": \"Average Sentiment\", \"created_at\": \"Date\", \"province\": \"Province\"},\n",
    "    \"line_shape\": \"spline\",\n",
    "    \"color_discrete_map\": PROVINCE_COLOR_MAP\n",
    "}\n",
    "fig = px.line(sentiment_avg,**args)\n",
    "fig.update_layout(**vis_args)\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-province_timeseries\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_sent_corr = sentiment_avg.pivot(index=\"created_at\",values=\"polarity_mean\",columns=\"province\").corr()\n",
    "prov_sent_corr.to_excel(\"../data/province_sentiment-correlation.xlsx\")\n",
    "corr_matrix = prov_sent_corr.to_numpy()\n",
    "labels = prov_sent_corr.columns\n",
    "for i in range(len(corr_matrix)):\n",
    "    corr_matrix[i,i] = None\n",
    "\n",
    "data = go.Heatmap(z=corr_matrix,y=labels,x=labels)\n",
    "fig = go.Figure(data=data,layout=vis_args)\n",
    "\n",
    "fp = f\"../visualizations/sentiment_analysis/{engine}-prov_sentiment_correlation\"\n",
    "with open(f\"{fp}.pdf\", \"wb\") as f:\n",
    "    f.write(scope.transform(fig, format=\"pdf\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "munk-covid",
   "language": "python",
   "name": "munk-covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
