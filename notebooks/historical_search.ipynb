{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining ‚õè\n",
    "\n",
    "**Purpose:** Collect all relevant Tweet's pertaining to the reopening of schools in the COVID-19 pandemic between Jan. 1, 2020 and Sept. 15, 2020.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Connect to Twitter's Search Tweets API, to the `full archive` endpoint\n",
    "2. Go province by province<sup>1</sup> and:\n",
    "    1. Collect all tweets that mention that an education minister\n",
    "    2. Collect all tweets that contain a dedicated list of keywords/hashtags\n",
    "3. Store collection of tweets in Pandas dataframe, and only keep relevant features (data, geocode, text, author, *etc.*)\n",
    "4. Add an extra column that is the cleaned tweet text.\n",
    "5. Save dataframe to CSV\n",
    "6. Solve the pandemic üéä\n",
    "\n",
    "\n",
    "<sup>1</sup> For more information on what tweets are geocoded, see [Twitter's geofiltering guide](https://developer.twitter.com/en/docs/tutorials/filtering-tweets-by-location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from searchtweets import collect_results, gen_rule_payload, load_credentials, ResultStream\n",
    "\n",
    "premium_search_args = load_credentials(filename=\"../secrets/new_secret.yaml\",yaml_key=\"search_tweets_api\",env_overwrite=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Filtering Rules\n",
    "\n",
    "**Query Rules:** Each aspect of the query (mentions, keywords, hashtags, geo, etc...) should be encapsulated in their own brackets. Each part of the query, *aside from geo*, only needs one part to be satisfied, so those are all ORed together. Since geo must be satisfied, the rest of the query is put in brackets and geo is appended at the end.\n",
    "\n",
    "**IMPORTANT** This does not work with the `sandbox` API tier so we need to pony up for `premium` first.\n",
    "\n",
    "To collect tweets from province $X$, search for tweets where the account profile has location containing $X$ **OR** geocoded tweets that fall in $X$ \n",
    "\n",
    "Note: the `geo` attribute is deprecated and is ignored accordingly. For geocoded tweets only the `place` attribute will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has geo AND one of these place markers\n",
    "country = '((has:geo OR has:profile_geo) (place_country:CA OR profile_country:CA))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Strategy\n",
    "*TODO: UPDATE*\n",
    "\n",
    "3 conditions that a tweet must satisfy\n",
    "1. It needs to be about the covid-19 pandemic (covid OR covid-19 OR coronavirus OR pandemic OR lockdown)\n",
    "2. It needs to be about children/parental anxiety (child OR children OR kid OR LO OR toddler OR parent OR family)\n",
    "3. It needs to be about school/the back to school season (school OR risk OR open OR reopen OR safe OR safety OR safely, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((covid) OR (covid-19) OR (coronavirus) OR (pandemic) OR (lockdown) OR (shutdown) OR (closure) OR (closures) OR (open) OR (reopen) OR (risk) OR (safe) OR (safety) OR (safely)) ((child) OR (children) OR (toddler) OR (toddlers) OR (kid) OR (kids) OR (mom) OR (moms) OR (mother) OR (mothers) OR (dad) OR (dads) OR (father) OR (fathers) OR (parent) OR (parents)) ((school) OR (schools) OR (preschools) OR (preschool) OR (daycare) OR (childcare) OR (class) OR (classroom) OR (classrooms) OR (cohort) OR ((online OR distance OR remote) learning)))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_filters = [\"covid\",\n",
    "                 \"covid-19\",\n",
    "                 \"coronavirus\",\n",
    "                 \"pandemic\",\n",
    "                 \"lockdown\",\n",
    "                 \"shutdown\",\n",
    "                 \"closure\",\n",
    "                 \"closures\",\n",
    "                 \"open\",\n",
    "                 \"reopen\",\n",
    "                 \"risk\",\n",
    "                 \"safe\",\n",
    "                 \"safety\",\n",
    "                 \"safely\"]\n",
    "\n",
    "covid_filters = \"((\"+\") OR (\".join(covid_filters)+\"))\"\n",
    "\n",
    "school_filters = [\"school\",\n",
    "          \"schools\",\n",
    "          \"preschools\",\n",
    "          \"preschool\",\n",
    "          \"daycare\",\n",
    "          \"childcare\",\n",
    "          \"class\",\n",
    "          \"classroom\",\n",
    "          \"classrooms\",\n",
    "          \"cohort\",\n",
    "          \"(online OR distance OR remote) learning\"]\n",
    "\n",
    "school_filters = \"((\"+\") OR (\".join(school_filters)+\"))\"\n",
    "\n",
    "child_filters = [\"child\",\n",
    "                 \"children\",\n",
    "                 \"toddler\",\n",
    "                 \"toddlers\",\n",
    "                 \"kid\",\n",
    "                 \"kids\",\n",
    "                 \"mom\",\n",
    "                 \"moms\",\n",
    "                 \"mother\",\n",
    "                 \"mothers\",\n",
    "                 \"dad\",\n",
    "                 \"dads\",\n",
    "                 \"father\",\n",
    "                 \"fathers\",\n",
    "                 \"parent\",\n",
    "                 \"parents\"]\n",
    "\n",
    "child_filters = \"((\"+\") OR (\".join(child_filters)+\"))\"\n",
    "\n",
    "keywords = \"(\"+\" \".join([covid_filters,child_filters,school_filters])+\")\"\n",
    "keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#safeseptember OR #safeseptemberAB OR #safeseptemberBC OR #SafeSeptemberMB OR #safeseptemberNB OR #safeseptemberNL OR #safeseptemberNS OR #safeseptemberON OR #safeseptemberPEI OR #safeseptemberQC OR #safeseptemberSK OR #safeseptemberYT OR #unsafeseptember OR #unsafeseptemberAB OR #unsafeseptemberBC OR #unsafeseptemberMB OR #unsafeseptemberNS OR #unsafeseptemberON OR #unsafeseptemberQC)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = [\n",
    "    '#safeseptember',\n",
    "    '#safeseptemberAB',\n",
    "    '#safeseptemberBC',\n",
    "    '#SafeSeptemberMB',\n",
    "    '#safeseptemberNB',\n",
    "    '#safeseptemberNL',\n",
    "    '#safeseptemberNS',\n",
    "    '#safeseptemberON',\n",
    "    '#safeseptemberPEI',\n",
    "    '#safeseptemberQC',\n",
    "    '#safeseptemberSK',\n",
    "    '#safeseptemberYT',\n",
    "    '#unsafeseptember',\n",
    "    '#unsafeseptemberAB',\n",
    "    '#unsafeseptemberBC',\n",
    "    '#unsafeseptemberMB',\n",
    "    '#unsafeseptemberNS',\n",
    "    '#unsafeseptemberON',\n",
    "    '#unsafeseptemberQC',\n",
    "]\n",
    "\n",
    "hashtags = \"(\"+\" OR \".join(hashtags)+\")\"\n",
    "hashtags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Tweets\n",
    "\n",
    "From: \n",
    "* March: 8, 20\n",
    "* April: 8, 20\n",
    "* May: 8, 20\n",
    "* June: 8, 20\n",
    "* July: 8, 20\n",
    "* August: 8, 20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def create_query(filters,geo=\"\",lang=\"en\"):\n",
    "    \"\"\"\n",
    "        Takes in a list of fully formed filters that can be satisfied in disjunction.\n",
    "    \"\"\"\n",
    "    lang = f\"lang:{lang}\"\n",
    "    filter_str = \" OR \".join(filters)\n",
    "    query = f\"({filter_str}) {lang} {geo}\"\n",
    "    return query.strip()\n",
    "\n",
    "\n",
    "def return_tweets(query,from_date,to_date,f_name=None):\n",
    "    name = f\"{from_date}_{to_date}\" if not f_name else f\"{f_name}-{from_date}_{to_date}\"\n",
    "    fp = \"../data/raw_data/{}.json\".format(name)\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp) as fin:\n",
    "            return json.load(fin),name\n",
    "    print(\"Making request\")\n",
    "    rule = gen_rule_payload(query,\n",
    "                        from_date=from_date, #UTC 2018-10-21 00:00\n",
    "                        to_date=to_date,\n",
    "                        results_per_call=500)\n",
    "    rs = ResultStream(rule_payload=rule,\n",
    "                  max_pages=1,\n",
    "#                   max_results=10**10,\n",
    "                  **premium_search_args)\n",
    "    tweets = list(rs.stream())\n",
    "    with open(fp, 'w') as fout:\n",
    "        json.dump(tweets,fout,indent=4)\n",
    "    return tweets,name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((covid) OR (covid-19) OR (coronavirus) OR (pandemic) OR (lockdown) OR (shutdown) OR (closure) OR (closures) OR (open) OR (reopen) OR (risk) OR (safe) OR (safety) OR (safely)) ((child) OR (children) OR (toddler) OR (toddlers) OR (kid) OR (kids) OR (mom) OR (moms) OR (mother) OR (mothers) OR (dad) OR (dads) OR (father) OR (fathers) OR (parent) OR (parents)) ((school) OR (schools) OR (preschools) OR (preschool) OR (daycare) OR (childcare) OR (class) OR (classroom) OR (classrooms) OR (cohort) OR ((online OR distance OR remote) learning))) OR (#safeseptember OR #safeseptemberAB OR #safeseptemberBC OR #SafeSeptemberMB OR #safeseptemberNB OR #safeseptemberNL OR #safeseptemberNS OR #safeseptemberON OR #safeseptemberPEI OR #safeseptemberQC OR #safeseptemberSK OR #safeseptemberYT OR #unsafeseptember OR #unsafeseptemberAB OR #unsafeseptemberBC OR #unsafeseptemberMB OR #unsafeseptemberNS OR #unsafeseptemberON OR #unsafeseptemberQC)) lang:en ((has:geo OR has:profile_geo) (place_country:CA OR profile_country:CA)) 1017\n"
     ]
    }
   ],
   "source": [
    "query = create_query([keywords,hashtags],country)\n",
    "from_date = \"2020-05-20\"\n",
    "to_date = \"2020-05-21\"\n",
    "print(query,len(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-05-20_2020-05-21'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets,f_name = return_tweets(query,from_date=from_date,to_date=to_date)\n",
    "f_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Tweets\n",
    "\n",
    "Feature constructing, tweet cleaning, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from utils import PROVINCES\n",
    "from unidecode import unidecode\n",
    "from math import isnan\n",
    "\n",
    "decode = lambda x : unidecode(x) if type(x) is str else x\n",
    "\n",
    "def clean_tweet(text,extended_tweet,retweeted_status=None):\n",
    "    if retweeted_status and type(retweeted_status) is dict:\n",
    "        retweeted_status = dict(retweeted_status)\n",
    "        cleaned = clean_tweet(retweeted_status.get(\"text\"),retweeted_status.get(\"extended_tweet\"))[:-1]\n",
    "        return (*cleaned,True)\n",
    "    if pd.isna(extended_tweet):\n",
    "        return clean_text(text), text, False\n",
    "    to_dict = dict(extended_tweet)\n",
    "    return clean_text(to_dict[\"full_text\"]),to_dict[\"full_text\"], False\n",
    "\n",
    "rex = re.compile(r'<a.*?>(.*?)</a>',re.S|re.M)\n",
    "def clean_source(source):\n",
    "    match = rex.match(source)\n",
    "    return match.groups()[0].strip()\n",
    "\n",
    "clean_user = lambda x : x[\"screen_name\"] if x[\"screen_name\"] else None\n",
    "\n",
    "def clean_entities(entities):\n",
    "    hashtags = [h[\"text\"] for h in entities[\"hashtags\"]] if entities[\"hashtags\"] else np.nan\n",
    "    urls = [h[\"expanded_url\"] for h in entities[\"urls\"]] if entities[\"urls\"] else np.nan\n",
    "    mentions = [h[\"screen_name\"] for h in entities[\"user_mentions\"]] if entities[\"user_mentions\"] else np.nan\n",
    "    return hashtags,urls,mentions\n",
    "\n",
    "in_province = lambda prov : prov in PROVINCES\n",
    "\n",
    "def check_user(user):\n",
    "    user = dict(user)\n",
    "    if \"derived\" in user and \"locations\" in user[\"derived\"]:\n",
    "        loc = dict(user)[\"derived\"][\"locations\"][0]\n",
    "        long_lat = loc.get(\"geo\").get(\"coordinates\")\n",
    "        city = loc.get(\"locality\",np.nan)\n",
    "        prov = loc.get(\"region\",np.nan)\n",
    "        city, prov = decode(city), decode(prov)\n",
    "        loc_tup = (city, prov,*long_lat)\n",
    "        return loc_tup\n",
    "    return (np.nan,np.nan,np.nan,np.nan)\n",
    "    \n",
    "def clean_location(place,user):\n",
    "    if place:\n",
    "        place = dict(place)\n",
    "        long_lat = place[\"bounding_box\"][\"coordinates\"][0][0]\n",
    "        split = [decode(l.strip()) for l in place[\"full_name\"].split(\",\")]\n",
    "        user_loc = check_user(user)\n",
    "        if len(split) == 2:\n",
    "            return tuple(split+long_lat) if in_province(split[-1]) else user_loc\n",
    "        ## AFAIK the only time there's more than 1 comma in a place field is when the place is labelled 'unorganized'\n",
    "        elif len(split) > 2:\n",
    "            # If the tweet location object is having problems and we can derive a user location, do so.\n",
    "            if not user_loc.count(np.nan) or not in_province(split[-1]):\n",
    "                return user_loc\n",
    "            return (np.nan,split[-1],*long_lat)\n",
    "        else:\n",
    "            # If the tweet location object is having problems and we can derive a user location, do so.\n",
    "            if not user_loc.count(np.nan):\n",
    "                return user_loc\n",
    "            return (split[0],np.nan,*long_lat)\n",
    "    else:\n",
    "        return check_user(user)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>original_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>city</th>\n",
       "      <th>province</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263256693846077441</th>\n",
       "      <td>Wed May 20 23:54:00 +0000 2020</td>\n",
       "      <td>bdrallahyani</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>[author, conclude, child, unlikely, main, driv...</td>\n",
       "      <td>The authorüá∏üá™ concluded; Children are unlikely ...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://twitter.com/i/web/status/126325669384...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-79.41630</td>\n",
       "      <td>43.70011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263255832554340353</th>\n",
       "      <td>Wed May 20 23:50:35 +0000 2020</td>\n",
       "      <td>HTSCACalderone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[kid, retain, much, learn, 2020, pandemic, rem...</td>\n",
       "      <td>‚ÄúKids won‚Äôt retain much of what they learn dur...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ELmagazine]</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-79.41630</td>\n",
       "      <td>43.70011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263255247184629760</th>\n",
       "      <td>Wed May 20 23:48:15 +0000 2020</td>\n",
       "      <td>GopieWilliam</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[definitely, send, kid, back, school, sure, ab...</td>\n",
       "      <td>Definitely not sending my kids back to school ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[PrashadVickram]</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-79.41630</td>\n",
       "      <td>43.70011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263255126573113344</th>\n",
       "      <td>Wed May 20 23:47:46 +0000 2020</td>\n",
       "      <td>rickmarc</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>[year, gaza, teach, neighborhood, child, miss,...</td>\n",
       "      <td>A 13-year-old in Gaza is teaching neighborhood...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Reuters]</td>\n",
       "      <td>West Vancouver</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>-123.16652</td>\n",
       "      <td>49.36672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263254376778543106</th>\n",
       "      <td>Wed May 20 23:44:48 +0000 2020</td>\n",
       "      <td>Embraxtalm</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[year, gaza, teach, neighborhood, child, miss,...</td>\n",
       "      <td>A 13-year-old in Gaza is teaching neighborhood...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Reuters]</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-79.41630</td>\n",
       "      <td>43.70011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         created_at     screen_name  \\\n",
       "id                                                                    \n",
       "1263256693846077441  Wed May 20 23:54:00 +0000 2020    bdrallahyani   \n",
       "1263255832554340353  Wed May 20 23:50:35 +0000 2020  HTSCACalderone   \n",
       "1263255247184629760  Wed May 20 23:48:15 +0000 2020    GopieWilliam   \n",
       "1263255126573113344  Wed May 20 23:47:46 +0000 2020        rickmarc   \n",
       "1263254376778543106  Wed May 20 23:44:48 +0000 2020      Embraxtalm   \n",
       "\n",
       "                                 source  \\\n",
       "id                                        \n",
       "1263256693846077441     Twitter Web App   \n",
       "1263255832554340353  Twitter for iPhone   \n",
       "1263255247184629760  Twitter for iPhone   \n",
       "1263255126573113344     Twitter Web App   \n",
       "1263254376778543106  Twitter for iPhone   \n",
       "\n",
       "                                                            clean_text  \\\n",
       "id                                                                       \n",
       "1263256693846077441  [author, conclude, child, unlikely, main, driv...   \n",
       "1263255832554340353  [kid, retain, much, learn, 2020, pandemic, rem...   \n",
       "1263255247184629760  [definitely, send, kid, back, school, sure, ab...   \n",
       "1263255126573113344  [year, gaza, teach, neighborhood, child, miss,...   \n",
       "1263254376778543106  [year, gaza, teach, neighborhood, child, miss,...   \n",
       "\n",
       "                                                         original_text  \\\n",
       "id                                                                       \n",
       "1263256693846077441  The authorüá∏üá™ concluded; Children are unlikely ...   \n",
       "1263255832554340353  ‚ÄúKids won‚Äôt retain much of what they learn dur...   \n",
       "1263255247184629760  Definitely not sending my kids back to school ...   \n",
       "1263255126573113344  A 13-year-old in Gaza is teaching neighborhood...   \n",
       "1263254376778543106  A 13-year-old in Gaza is teaching neighborhood...   \n",
       "\n",
       "                     is_retweet  favorite_count  retweet_count hashtags  \\\n",
       "id                                                                        \n",
       "1263256693846077441       False               4              1      NaN   \n",
       "1263255832554340353        True               0              0      NaN   \n",
       "1263255247184629760        True               0              0      NaN   \n",
       "1263255126573113344        True               0              0      NaN   \n",
       "1263254376778543106        True               0              0      NaN   \n",
       "\n",
       "                                                                  urls  \\\n",
       "id                                                                       \n",
       "1263256693846077441  [https://twitter.com/i/web/status/126325669384...   \n",
       "1263255832554340353                                                NaN   \n",
       "1263255247184629760                                                NaN   \n",
       "1263255126573113344                                                NaN   \n",
       "1263254376778543106                                                NaN   \n",
       "\n",
       "                             mentions            city          province  \\\n",
       "id                                                                        \n",
       "1263256693846077441               NaN         Toronto           Ontario   \n",
       "1263255832554340353      [ELmagazine]         Toronto           Ontario   \n",
       "1263255247184629760  [PrashadVickram]         Toronto           Ontario   \n",
       "1263255126573113344         [Reuters]  West Vancouver  British Columbia   \n",
       "1263254376778543106         [Reuters]         Toronto           Ontario   \n",
       "\n",
       "                     longitude  latitude  \n",
       "id                                        \n",
       "1263256693846077441  -79.41630  43.70011  \n",
       "1263255832554340353  -79.41630  43.70011  \n",
       "1263255247184629760  -79.41630  43.70011  \n",
       "1263255126573113344 -123.16652  49.36672  \n",
       "1263254376778543106  -79.41630  43.70011  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_cleaning import clean_text\n",
    "clean_fp = \"../data/processed_data/{}.csv\".format(f_name)\n",
    "cov_tweets = pd.DataFrame(tweets)\n",
    "cov_tweets = cov_tweets[['id','user','created_at', 'source', 'text','extended_tweet','retweeted_status','place','entities','favorite_count', 'retweet_count']].set_index(\"id\")\n",
    "# Get twitter handle from user\n",
    "cov_tweets[\"screen_name\"] = cov_tweets[\"user\"].apply(clean_user)\n",
    "# clean the tweet text\n",
    "cov_tweets[[\"text\",\"extended_tweet\",\"is_retweet\"]] = cov_tweets[[\"text\",\"extended_tweet\",\"retweeted_status\"]].apply(lambda x: clean_tweet(*x),axis=1,result_type=\"expand\")\n",
    "cov_tweets = cov_tweets.rename({\"text\": \"clean_text\",\"extended_tweet\":\"original_text\"},axis=1)\n",
    "# Get the city/province from the location data\n",
    "cov_tweets[[\"city\",\"province\",\"longitude\",\"latitude\"]] = cov_tweets[[\"place\",\"user\"]].apply(lambda x : clean_location(*x),axis=1,result_type=\"expand\")\n",
    "cov_tweets = cov_tweets.drop([\"place\",\"user\"],axis=1)\n",
    "# Through what medium did they post the tweet?\n",
    "cov_tweets[\"source\"] = cov_tweets[\"source\"].apply(clean_source)\n",
    "# Extract tweet entities (hashtags, linked urls, etc...)\n",
    "cov_tweets[[\"hashtags\",\"urls\",\"mentions\"]] = cov_tweets[[\"entities\"]].apply(lambda x : clean_entities(x[\"entities\"]),result_type=\"expand\",axis=1)\n",
    "cov_tweets = cov_tweets.drop(\"entities\",axis=1)\n",
    "cov_tweets = cov_tweets[[\"created_at\",\"screen_name\",\"source\",\"clean_text\",\"original_text\",\"is_retweet\",\"favorite_count\",\"retweet_count\",\"hashtags\",\"urls\",\"mentions\",\"city\",\"province\",\"longitude\",\"latitude\"]]\n",
    "cov_tweets.to_csv(clean_fp)\n",
    "cov_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561 439 61 61\n"
     ]
    }
   ],
   "source": [
    "from_dates = [\"2020-05-20\"]\n",
    "to_dates = [\"2020-05-21\"]\n",
    "\n",
    "old_fp = \"../data/processed_data/new_search-{}_{}.csv\"\n",
    "new_fp = \"../data/processed_data/newest_search-{}_{}.csv\"\n",
    "\n",
    "old_data = [pd.read_csv(old_fp.format(*f),parse_dates=[\"created_at\"],header=0) for f in zip(from_dates,to_dates)]\n",
    "new_data = [pd.read_csv(new_fp.format(*f),parse_dates=[\"created_at\"],header=0) for f in zip(from_dates,to_dates)]\n",
    "old_data = pd.concat(old_data, axis=0,ignore_index=True).set_index(\"id\").sort_values(\"created_at\")\n",
    "new_data = pd.concat(new_data, axis=0,ignore_index=True).set_index(\"id\").sort_values(\"created_at\")\n",
    "\n",
    "columns = old_data.columns\n",
    "merged = pd.merge(old_data, new_data,left_index=True, right_index=True,how=\"outer\",indicator=True)\n",
    "inner = merged[merged['_merge']=='both']\n",
    "only_old = merged[merged['_merge']=='left_only']\n",
    "only_new = merged[merged['_merge']=='right_only']\n",
    "print(len(merged),len(inner),len(only_old),len(only_new))\n",
    "only_old = only_old[[f\"{x}_x\" for x in columns]]\n",
    "only_new = only_new[[f\"{x}_y\" for x in columns]]\n",
    "inner = inner[[f\"{x}_y\" for x in columns]]\n",
    "only_old.columns,only_new.columns,inner.columns = columns,columns,columns\n",
    "only_old\n",
    "\n",
    "only_old.to_csv(\"../data/t-only_matches_new_queries.csv\")\n",
    "only_new.to_csv(\"../data/t-only_matches_newest_queries.csv\")\n",
    "inner.to_csv(\"../data/matches_both_nn_queries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Politician Mentions\n",
    "Must @ a politician (premier or education minister) and be pertinent to covid AND school reopenings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((@jkenney OR @jjhorgan OR @BrianPallister OR @blainehiggs OR @PremierofNL OR @CCochrane_NWT OR @StephenMcNeil OR @JSavikataaq OR @fordnation OR @dennyking OR @francoislegault OR @PremierScottMoe OR @Premier_Silver OR @davideggenAB OR @Rob_Fleming OR @mingoertzen OR @DominicCardy OR @BrianWarr709 OR @RJSimpson_NWT OR @zachchurchill OR @Sflecce OR @bradtrivers OR @jfrobergeQc OR @GordWyant OR @TracyMcPheeRS) (((covid) OR (covid-19) OR (coronavirus) OR (pandemic) OR (lockdown) OR (shutdown) OR (closure) OR (closures) OR (open) OR (reopen) OR (risk) OR (safe) OR (safety) OR (safely)) ((child) OR (children) OR (toddler) OR (toddlers) OR (kid) OR (kids) OR (mom) OR (moms) OR (dad) OR (dads) OR (parent) OR (parents))))) lang:en ((has:geo OR has:profile_geo) (place_country:CA OR profile_country:CA)) 804\n"
     ]
    }
   ],
   "source": [
    "edu_minister_dict = {\n",
    "    \"AB\": \"@davideggenAB\",\n",
    "    \"BC\": \"@Rob_Fleming\",\n",
    "    \"MB\": \"@mingoertzen\",\n",
    "    \"NB\": \"@DominicCardy\",\n",
    "    \"NL\": \"@BrianWarr709\",\n",
    "    \"NT\": \"@RJSimpson_NWT\",\n",
    "    \"NS\": \"@zachchurchill\",\n",
    "    \"ON\": \"@Sflecce\",\n",
    "    \"PEI\": \"@bradtrivers\",\n",
    "    \"QC\": \"@jfrobergeQc\",\n",
    "    \"SK\": \"@GordWyant\",\n",
    "    \"YT\": \"@TracyMcPheeRS\"\n",
    "}\n",
    "\n",
    "premier_dict = {\n",
    "    \"AB\": \"@jkenney\",\n",
    "    \"BC\": \"@jjhorgan\",\n",
    "    \"MB\": \"@BrianPallister\",\n",
    "    \"NB\": \"@blainehiggs\",\n",
    "    \"NL\": \"@PremierofNL\",\n",
    "    \"NT\": \"@CCochrane_NWT\",\n",
    "    \"NS\": \"@StephenMcNeil\",\n",
    "    \"NU\": \"@JSavikataaq\",\n",
    "    \"ON\": \"@fordnation\",\n",
    "    \"PEI\": \"@dennyking\",\n",
    "    \"QC\": \"@francoislegault\",\n",
    "    \"SK\": \"@PremierScottMoe\",\n",
    "    \"YT\": \"@Premier_Silver\"\n",
    "}\n",
    "\n",
    "politicians = \" OR \".join([val for _,val in list(premier_dict.items())+list(edu_minister_dict.items())])\n",
    "\n",
    "politicians = f\"(({politicians}) ({covid_filters} {child_filters}))\"\n",
    "query = create_query([politicians],country)\n",
    "from_date = \"2020-08-17\"\n",
    "to_date = \"2020-08-18\"\n",
    "print(query,len(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
