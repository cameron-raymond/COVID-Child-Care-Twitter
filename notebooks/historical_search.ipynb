{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining ‚õè\n",
    "\n",
    "**Purpose:** Collect all relevant Tweet's pertaining to the reopening of schools in the COVID-19 pandemic between Jan. 1, 2020 and Sept. 15, 2020.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Connect to Twitter's Search Tweets API, to the `full archive` endpoint\n",
    "2. Go province by province<sup>1</sup> and:\n",
    "    1. Collect all tweets that mention that an education minister\n",
    "    2. Collect all tweets that contain a dedicated list of keywords/hashtags\n",
    "3. Store collection of tweets in Pandas dataframe, and only keep relevant features (data, geocode, text, author, *etc.*)\n",
    "4. Add an extra column that is the cleaned tweet text.\n",
    "5. Save dataframe to CSV\n",
    "6. Solve the pandemic üéä\n",
    "\n",
    "\n",
    "<sup>1</sup> For more information on what tweets are geocoded, see [Twitter's geofiltering guide](https://developer.twitter.com/en/docs/tutorials/filtering-tweets-by-location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from searchtweets import collect_results, gen_rule_payload, load_credentials, ResultStream\n",
    "\n",
    "premium_search_args = load_credentials(filename=\"../secrets/new_secret.yaml\",yaml_key=\"search_tweets_api\",env_overwrite=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Filtering Rules\n",
    "\n",
    "**Query Rules:** Each aspect of the query (mentions, keywords, hashtags, geo, etc...) should be encapsulated in their own brackets. Each part of the query, *aside from geo*, only needs one part to be satisfied, so those are all ORed together. Since geo must be satisfied, the rest of the query is put in brackets and geo is appended at the end.\n",
    "\n",
    "**IMPORTANT** This does not work with the `sandbox` API tier so we need to pony up for `premium` first.\n",
    "\n",
    "To collect tweets from province $X$, search for tweets where the account profile has location containing $X$ **OR** geocoded tweets that fall in $X$ \n",
    "\n",
    "Note: the `geo` attribute is deprecated and is ignored accordingly. For geocoded tweets only the `place` attribute will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has geo AND one of these place markers\n",
    "country = '((has:geo OR has:profile_geo) (place_country:CA OR profile_country:CA))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Strategy\n",
    "*TODO: UPDATE*\n",
    "\n",
    "3 conditions that a tweet must satisfy\n",
    "1. It needs to be about the covid-19 pandemic (covid OR covid-19 OR coronavirus OR pandemic OR lockdown)\n",
    "2. It needs to be about children/parental anxiety (child OR children OR kid OR LO OR toddler OR parent OR family)\n",
    "3. It needs to be about school/the back to school season (school OR risk OR open OR reopen OR safe OR safety OR safely, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((covid) OR (covid-19) OR (coronavirus) OR (pandemic) OR (lockdown) OR (shutdown) OR (closure) OR (closures) OR (open) OR (reopen) OR (risk) OR (safe) OR (safety) OR (safely)) ((child) OR (children) OR (toddler) OR (toddlers) OR (kid) OR (kids) OR (mom) OR (moms) OR (mother) OR (mothers) OR (dad) OR (dads) OR (father) OR (fathers) OR (parent) OR (parents)) ((school) OR (schools) OR (preschools) OR (preschool) OR (daycare) OR (childcare) OR (class) OR (classroom) OR (classrooms) OR (cohort) OR ((online OR distance OR remote) learning)))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_filters = [\"covid\",\n",
    "                 \"covid-19\",\n",
    "                 \"coronavirus\",\n",
    "                 \"pandemic\",\n",
    "                 \"lockdown\",\n",
    "                 \"shutdown\",\n",
    "                 \"closure\",\n",
    "                 \"closures\",\n",
    "                 \"open\",\n",
    "                 \"reopen\",\n",
    "                 \"risk\",\n",
    "                 \"safe\",\n",
    "                 \"safety\",\n",
    "                 \"safely\"]\n",
    "\n",
    "covid_filters = \"((\"+\") OR (\".join(covid_filters)+\"))\"\n",
    "\n",
    "school_filters = [\"school\",\n",
    "          \"schools\",\n",
    "          \"preschools\",\n",
    "          \"preschool\",\n",
    "          \"daycare\",\n",
    "          \"childcare\",\n",
    "          \"class\",\n",
    "          \"classroom\",\n",
    "          \"classrooms\",\n",
    "          \"cohort\",\n",
    "          \"(online OR distance OR remote) learning\"]\n",
    "\n",
    "school_filters = \"((\"+\") OR (\".join(school_filters)+\"))\"\n",
    "\n",
    "child_filters = [\"child\",\n",
    "                 \"children\",\n",
    "                 \"toddler\",\n",
    "                 \"toddlers\",\n",
    "                 \"kid\",\n",
    "                 \"kids\",\n",
    "                 \"mom\",\n",
    "                 \"moms\",\n",
    "                 \"mother\",\n",
    "                 \"mothers\",\n",
    "                 \"dad\",\n",
    "                 \"dads\",\n",
    "                 \"father\",\n",
    "                 \"fathers\",\n",
    "                 \"parent\",\n",
    "                 \"parents\"]\n",
    "\n",
    "child_filters = \"((\"+\") OR (\".join(child_filters)+\"))\"\n",
    "\n",
    "keywords = \"(\"+\" \".join([covid_filters,child_filters,school_filters])+\")\"\n",
    "keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#safeseptember OR #safeseptemberAB OR #safeseptemberBC OR #SafeSeptemberMB OR #safeseptemberNB OR #safeseptemberNL OR #safeseptemberNS OR #safeseptemberON OR #safeseptemberPEI OR #safeseptemberQC OR #safeseptemberSK OR #safeseptemberYT OR #unsafeseptember OR #unsafeseptemberAB OR #unsafeseptemberBC OR #unsafeseptemberMB OR #unsafeseptemberNS OR #unsafeseptemberON OR #unsafeseptemberQC)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = [\n",
    "    '#safeseptember',\n",
    "    '#safeseptemberAB',\n",
    "    '#safeseptemberBC',\n",
    "    '#SafeSeptemberMB',\n",
    "    '#safeseptemberNB',\n",
    "    '#safeseptemberNL',\n",
    "    '#safeseptemberNS',\n",
    "    '#safeseptemberON',\n",
    "    '#safeseptemberPEI',\n",
    "    '#safeseptemberQC',\n",
    "    '#safeseptemberSK',\n",
    "    '#safeseptemberYT',\n",
    "    '#unsafeseptember',\n",
    "    '#unsafeseptemberAB',\n",
    "    '#unsafeseptemberBC',\n",
    "    '#unsafeseptemberMB',\n",
    "    '#unsafeseptemberNS',\n",
    "    '#unsafeseptemberON',\n",
    "    '#unsafeseptemberQC',\n",
    "]\n",
    "\n",
    "hashtags = \"(\"+\" OR \".join(hashtags)+\")\"\n",
    "hashtags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Tweets\n",
    "\n",
    "From: \n",
    "* March: 8, 20\n",
    "* April: 8, 20\n",
    "* May: 8, 20\n",
    "* June: 8, 20\n",
    "* July: 8, 20\n",
    "* August: 8, 20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def create_query(filters,geo=\"\",lang=\"en\"):\n",
    "    \"\"\"\n",
    "        Takes in a list of fully formed filters that can be satisfied in disjunction.\n",
    "    \"\"\"\n",
    "    lang = f\"lang:{lang}\"\n",
    "    filter_str = \" OR \".join(filters)\n",
    "    query = f\"({filter_str}) {lang} {geo}\"\n",
    "    return query.strip()\n",
    "\n",
    "\n",
    "def return_tweets(query,from_date,to_date,f_name=None,max_pages=1):\n",
    "    name = f\"{from_date}_{to_date}\" if not f_name else f\"{f_name}-{from_date}_{to_date}\"\n",
    "    fp = \"../data/raw_data/{}.json\".format(name)\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp) as fin:\n",
    "            return json.load(fin),name\n",
    "    print(f\"Making request: {name}\")\n",
    "    rule = gen_rule_payload(query,\n",
    "                        from_date=from_date, #UTC 2018-10-21 00:00\n",
    "                        to_date=to_date,\n",
    "                        results_per_call=500)\n",
    "    rs = ResultStream(rule_payload=rule,\n",
    "                  max_pages=max_pages,\n",
    "                  max_results=10**10,\n",
    "                  **premium_search_args)\n",
    "    tweets = list(rs.stream())\n",
    "    with open(fp, 'w') as fout:\n",
    "        json.dump(tweets,fout,indent=4)\n",
    "    return tweets,name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((covid) OR (covid-19) OR (coronavirus) OR (pandemic) OR (lockdown) OR (shutdown) OR (closure) OR (closures) OR (open) OR (reopen) OR (risk) OR (safe) OR (safety) OR (safely)) ((child) OR (children) OR (toddler) OR (toddlers) OR (kid) OR (kids) OR (mom) OR (moms) OR (mother) OR (mothers) OR (dad) OR (dads) OR (father) OR (fathers) OR (parent) OR (parents)) ((school) OR (schools) OR (preschools) OR (preschool) OR (daycare) OR (childcare) OR (class) OR (classroom) OR (classrooms) OR (cohort) OR ((online OR distance OR remote) learning))) OR (#safeseptember OR #safeseptemberAB OR #safeseptemberBC OR #SafeSeptemberMB OR #safeseptemberNB OR #safeseptemberNL OR #safeseptemberNS OR #safeseptemberON OR #safeseptemberPEI OR #safeseptemberQC OR #safeseptemberSK OR #safeseptemberYT OR #unsafeseptember OR #unsafeseptemberAB OR #unsafeseptemberBC OR #unsafeseptemberMB OR #unsafeseptemberNS OR #unsafeseptemberON OR #unsafeseptemberQC)) lang:en ((has:geo OR has:profile_geo) (place_country:CA OR profile_country:CA)) 1017\n"
     ]
    }
   ],
   "source": [
    "query = create_query([keywords,hashtags],country)\n",
    "from_date = \"2020-07-15\"\n",
    "to_date = \"2020-08-08\"\n",
    "print(query,len(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets,f_name = return_tweets(query,from_date=from_date,to_date=to_date,max_pages=500)\n",
    "f_name,len(tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Tweets\n",
    "\n",
    "Feature constructing, tweet cleaning, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DTYPE, PARSE_DATES, PROVINCES,CONVERTERS\n",
    "from text_cleaning import clean_text\n",
    "from unidecode import unidecode\n",
    "from math import isnan\n",
    "import re\n",
    "\n",
    "decode = lambda x : unidecode(x) if type(x) is str else x\n",
    "\n",
    "def clean_tweet(text,extended_tweet,retweeted_status=None):\n",
    "    if retweeted_status and type(retweeted_status) is dict:\n",
    "        retweeted_status = dict(retweeted_status)\n",
    "        cleaned = clean_tweet(retweeted_status.get(\"text\"),retweeted_status.get(\"extended_tweet\"))[:-1]\n",
    "        return (*cleaned,True)\n",
    "    if pd.isna(extended_tweet):\n",
    "        return clean_text(text), text, False\n",
    "    to_dict = dict(extended_tweet)\n",
    "    return clean_text(to_dict[\"full_text\"]),to_dict[\"full_text\"], False\n",
    "\n",
    "rex = re.compile(r'<a.*?>(.*?)</a>',re.S|re.M)\n",
    "def clean_source(source):\n",
    "    if source:\n",
    "        match = rex.match(source)\n",
    "        return match.groups()[0].strip()\n",
    "    return np.nan\n",
    "\n",
    "clean_user = lambda x : x[\"screen_name\"] if x[\"screen_name\"] else None\n",
    "\n",
    "def clean_entities(entities):\n",
    "    hashtags = [h[\"text\"] for h in entities[\"hashtags\"]] if entities[\"hashtags\"] else np.nan\n",
    "    urls = [h[\"expanded_url\"] for h in entities[\"urls\"]] if entities[\"urls\"] else np.nan\n",
    "    mentions = [h[\"screen_name\"] for h in entities[\"user_mentions\"]] if entities[\"user_mentions\"] else np.nan\n",
    "    return hashtags,urls,mentions\n",
    "\n",
    "in_province = lambda prov : prov in PROVINCES\n",
    "\n",
    "def check_user(user):\n",
    "    user = dict(user)\n",
    "    if \"derived\" in user and \"locations\" in user[\"derived\"]:\n",
    "        loc = dict(user)[\"derived\"][\"locations\"][0]\n",
    "        long_lat = loc.get(\"geo\").get(\"coordinates\")\n",
    "        city = loc.get(\"locality\",np.nan)\n",
    "        prov = loc.get(\"region\",np.nan)\n",
    "        city, prov = decode(city), decode(prov)\n",
    "        loc_tup = (city, prov,*long_lat)\n",
    "        return loc_tup\n",
    "    return (np.nan,np.nan,np.nan,np.nan)\n",
    "    \n",
    "def clean_location(place,user):\n",
    "    if place:\n",
    "        place = dict(place)\n",
    "        long_lat = place[\"bounding_box\"][\"coordinates\"][0][0]\n",
    "        split = [decode(l.strip()) for l in place[\"full_name\"].split(\",\")]\n",
    "        user_loc = check_user(user)\n",
    "        if len(split) == 2:\n",
    "            return tuple(split+long_lat) if in_province(split[-1]) else user_loc\n",
    "        ## AFAIK the only time there's more than 1 comma in a place field is when the place is labelled 'unorganized'\n",
    "        elif len(split) > 2:\n",
    "            # If the tweet location object is having problems and we can derive a user location, do so.\n",
    "            if not user_loc.count(np.nan) or not in_province(split[-1]):\n",
    "                return user_loc\n",
    "            return (np.nan,split[-1],*long_lat)\n",
    "        else:\n",
    "            # If the tweet location object is having problems and we can derive a user location, do so.\n",
    "            if not user_loc.count(np.nan):\n",
    "                return user_loc\n",
    "            return (split[0],np.nan,*long_lat)\n",
    "    else:\n",
    "        return check_user(user)\n",
    "\n",
    "def JSON_to_CSV(f_name):\n",
    "    clean_fp = \"../data/processed_data/{}.csv\".format(f_name)\n",
    "    ## IF the file csv already exists don't waste time doing all the cleaning again\n",
    "    if os.path.isfile(clean_fp):\n",
    "        return pd.read_csv(clean_fp,\n",
    "                           index_col=0,\n",
    "                           header=0,\n",
    "                           dtype=DTYPE,\n",
    "                           converters=CONVERTERS,\n",
    "                           parse_dates=PARSE_DATES)\n",
    "    # If the zipped file already exists unzip it, write the plain file to the local storage and return the dataframe\n",
    "    if os.path.isfile(clean_fp+\".gz\"):\n",
    "        cov_tweets = pd.read_csv(clean_fp+\".gz\",\n",
    "                                 index_col=0,\n",
    "                                 header=0,\n",
    "                                 compression='gzip',\n",
    "                                 dtype=DTYPE,\n",
    "                                 converters=CONVERTERS,\n",
    "                                 parse_dates=PARSE_DATES)\n",
    "        cov_tweets.to_csv(clean_fp)\n",
    "        return cov_tweets\n",
    "    cov_tweets = pd.DataFrame(tweets)\n",
    "    cov_tweets = cov_tweets[['id','user','created_at', 'source', 'text','extended_tweet','retweeted_status','place','entities','favorite_count', 'retweet_count']].set_index(\"id\")\n",
    "    # Get twitter handle from user\n",
    "    cov_tweets[\"screen_name\"] = cov_tweets[\"user\"].apply(clean_user)\n",
    "    # clean the tweet text\n",
    "    cov_tweets[[\"text\",\"extended_tweet\",\"is_retweet\"]] = cov_tweets[[\"text\",\"extended_tweet\",\"retweeted_status\"]].apply(lambda x: clean_tweet(*x),axis=1,result_type=\"expand\")\n",
    "    cov_tweets = cov_tweets.rename({\"text\": \"clean_text\",\"extended_tweet\":\"original_text\"},axis=1)\n",
    "    # Get the city/province from the location data\n",
    "    cov_tweets[[\"city\",\"province\",\"longitude\",\"latitude\"]] = cov_tweets[[\"place\",\"user\"]].apply(lambda x : clean_location(*x),axis=1,result_type=\"expand\")\n",
    "    cov_tweets = cov_tweets.drop([\"place\",\"user\"],axis=1)\n",
    "    # Through what medium did they post the tweet?\n",
    "    cov_tweets[\"source\"] = cov_tweets[\"source\"].apply(clean_source)\n",
    "    # Extract tweet entities (hashtags, linked urls, etc...)\n",
    "    cov_tweets[[\"hashtags\",\"urls\",\"mentions\"]] = cov_tweets[[\"entities\"]].apply(lambda x : clean_entities(x[\"entities\"]),result_type=\"expand\",axis=1)\n",
    "    cov_tweets = cov_tweets.drop(\"entities\",axis=1)\n",
    "    cov_tweets = cov_tweets[[\"created_at\",\"screen_name\",\"source\",\"clean_text\",\"original_text\",\"is_retweet\",\"favorite_count\",\"retweet_count\",\"hashtags\",\"urls\",\"mentions\",\"city\",\"province\",\"longitude\",\"latitude\"]]\n",
    "    cov_tweets.to_csv(clean_fp+\".gz\",compression='gzip')\n",
    "    cov_tweets.to_csv(clean_fp)\n",
    "    return cov_tweets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>original_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>city</th>\n",
       "      <th>province</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1291886800957579264</th>\n",
       "      <td>Fri Aug 07 23:59:50 +0000 2020</td>\n",
       "      <td>faithkot</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>4321gary karenetfodotl fordnation sflecce reco...</td>\n",
       "      <td>@4321Gary @KarenETFODOTL @fordnation @Sflecce ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://twitter.com/i/web/status/129188680095...</td>\n",
       "      <td>[4321Gary, KarenETFODOTL, fordnation, Sflecce]</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-79.84963</td>\n",
       "      <td>43.25011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291886780468416512</th>\n",
       "      <td>Fri Aug 07 23:59:45 +0000 2020</td>\n",
       "      <td>ReceKim</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>laurelliddicoat sflecce plan keep childcare wo...</td>\n",
       "      <td>@LaurelLiddicoat @Sflecce No his plan does not...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://twitter.com/i/web/status/129188678046...</td>\n",
       "      <td>[LaurelLiddicoat, Sflecce]</td>\n",
       "      <td>Oshawa</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-78.84957</td>\n",
       "      <td>43.90012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291886482974576640</th>\n",
       "      <td>Fri Aug 07 23:58:34 +0000 2020</td>\n",
       "      <td>mrjbeeds</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>protest hold across saskatchewan friday parent...</td>\n",
       "      <td>Protests were held across Saskatchewan on Frid...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[GlobalSaskatoon]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>-125.00320</td>\n",
       "      <td>53.99983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291886446152908802</th>\n",
       "      <td>Fri Aug 07 23:58:25 +0000 2020</td>\n",
       "      <td>SLBM2006</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>wish people money time connection often send k...</td>\n",
       "      <td>I wish that people with money, time, and conne...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[realsarahpolley]</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-79.84963</td>\n",
       "      <td>43.25011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291886384463011842</th>\n",
       "      <td>Fri Aug 07 23:58:10 +0000 2020</td>\n",
       "      <td>EveryAlbertan</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>thebluegem3 give career parent complex kid kno...</td>\n",
       "      <td>@TheBlueGem3 I had to give up my career yrs ag...</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://twitter.com/i/web/status/129188638446...</td>\n",
       "      <td>[TheBlueGem3]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>-117.46900</td>\n",
       "      <td>52.28333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         created_at    screen_name  \\\n",
       "id                                                                   \n",
       "1291886800957579264  Fri Aug 07 23:59:50 +0000 2020       faithkot   \n",
       "1291886780468416512  Fri Aug 07 23:59:45 +0000 2020        ReceKim   \n",
       "1291886482974576640  Fri Aug 07 23:58:34 +0000 2020       mrjbeeds   \n",
       "1291886446152908802  Fri Aug 07 23:58:25 +0000 2020       SLBM2006   \n",
       "1291886384463011842  Fri Aug 07 23:58:10 +0000 2020  EveryAlbertan   \n",
       "\n",
       "                                  source  \\\n",
       "id                                         \n",
       "1291886800957579264   Twitter for iPhone   \n",
       "1291886780468416512   Twitter for iPhone   \n",
       "1291886482974576640   Twitter for iPhone   \n",
       "1291886446152908802   Twitter for iPhone   \n",
       "1291886384463011842  Twitter for Android   \n",
       "\n",
       "                                                            clean_text  \\\n",
       "id                                                                       \n",
       "1291886800957579264  4321gary karenetfodotl fordnation sflecce reco...   \n",
       "1291886780468416512  laurelliddicoat sflecce plan keep childcare wo...   \n",
       "1291886482974576640  protest hold across saskatchewan friday parent...   \n",
       "1291886446152908802  wish people money time connection often send k...   \n",
       "1291886384463011842  thebluegem3 give career parent complex kid kno...   \n",
       "\n",
       "                                                         original_text  \\\n",
       "id                                                                       \n",
       "1291886800957579264  @4321Gary @KarenETFODOTL @fordnation @Sflecce ...   \n",
       "1291886780468416512  @LaurelLiddicoat @Sflecce No his plan does not...   \n",
       "1291886482974576640  Protests were held across Saskatchewan on Frid...   \n",
       "1291886446152908802  I wish that people with money, time, and conne...   \n",
       "1291886384463011842  @TheBlueGem3 I had to give up my career yrs ag...   \n",
       "\n",
       "                     is_retweet  favorite_count  retweet_count hashtags  \\\n",
       "id                                                                        \n",
       "1291886800957579264       False               1              0      NaN   \n",
       "1291886780468416512       False               3              0      NaN   \n",
       "1291886482974576640        True               0              0      NaN   \n",
       "1291886446152908802        True               0              0      NaN   \n",
       "1291886384463011842       False              37              4      NaN   \n",
       "\n",
       "                                                                  urls  \\\n",
       "id                                                                       \n",
       "1291886800957579264  [https://twitter.com/i/web/status/129188680095...   \n",
       "1291886780468416512  [https://twitter.com/i/web/status/129188678046...   \n",
       "1291886482974576640                                                NaN   \n",
       "1291886446152908802                                                NaN   \n",
       "1291886384463011842  [https://twitter.com/i/web/status/129188638446...   \n",
       "\n",
       "                                                           mentions      city  \\\n",
       "id                                                                              \n",
       "1291886800957579264  [4321Gary, KarenETFODOTL, fordnation, Sflecce]  Hamilton   \n",
       "1291886780468416512                      [LaurelLiddicoat, Sflecce]    Oshawa   \n",
       "1291886482974576640                               [GlobalSaskatoon]       NaN   \n",
       "1291886446152908802                               [realsarahpolley]  Hamilton   \n",
       "1291886384463011842                                   [TheBlueGem3]       NaN   \n",
       "\n",
       "                             province  longitude  latitude  \n",
       "id                                                          \n",
       "1291886800957579264           Ontario  -79.84963  43.25011  \n",
       "1291886780468416512           Ontario  -78.84957  43.90012  \n",
       "1291886482974576640  British Columbia -125.00320  53.99983  \n",
       "1291886446152908802           Ontario  -79.84963  43.25011  \n",
       "1291886384463011842           Alberta -117.46900  52.28333  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_tweets = JSON_to_CSV(f_name)\n",
    "cov_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Politician Mentions\n",
    "Must @ a politician (premier or education minister) and be pertinent to covid AND school reopenings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((@jkenney OR @jjhorgan OR @BrianPallister OR @blainehiggs OR @PremierofNL OR @CCochrane_NWT OR @StephenMcNeil OR @JSavikataaq OR @fordnation OR @dennyking OR @francoislegault OR @PremierScottMoe OR @Premier_Silver OR @davideggenAB OR @Rob_Fleming OR @mingoertzen OR @DominicCardy OR @BrianWarr709 OR @RJSimpson_NWT OR @zachchurchill OR @Sflecce OR @bradtrivers OR @jfrobergeQc OR @GordWyant OR @TracyMcPheeRS) (((covid) OR (covid-19) OR (coronavirus) OR (pandemic) OR (lockdown) OR (shutdown) OR (closure) OR (closures) OR (open) OR (reopen) OR (risk) OR (safe) OR (safety) OR (safely)) ((child) OR (children) OR (toddler) OR (toddlers) OR (kid) OR (kids) OR (mom) OR (moms) OR (mother) OR (mothers) OR (dad) OR (dads) OR (father) OR (fathers) OR (parent) OR (parents))))) lang:en ((has:geo OR has:profile_geo) (place_country:CA OR profile_country:CA)) 854\n"
     ]
    }
   ],
   "source": [
    "edu_minister_dict = {\n",
    "    \"AB\": \"@davideggenAB\",\n",
    "    \"BC\": \"@Rob_Fleming\",\n",
    "    \"MB\": \"@mingoertzen\",\n",
    "    \"NB\": \"@DominicCardy\",\n",
    "    \"NL\": \"@BrianWarr709\",\n",
    "    \"NT\": \"@RJSimpson_NWT\",\n",
    "    \"NS\": \"@zachchurchill\",\n",
    "    \"ON\": \"@Sflecce\",\n",
    "    \"PEI\": \"@bradtrivers\",\n",
    "    \"QC\": \"@jfrobergeQc\",\n",
    "    \"SK\": \"@GordWyant\",\n",
    "    \"YT\": \"@TracyMcPheeRS\"\n",
    "}\n",
    "\n",
    "premier_dict = {\n",
    "    \"AB\": \"@jkenney\",\n",
    "    \"BC\": \"@jjhorgan\",\n",
    "    \"MB\": \"@BrianPallister\",\n",
    "    \"NB\": \"@blainehiggs\",\n",
    "    \"NL\": \"@PremierofNL\",\n",
    "    \"NT\": \"@CCochrane_NWT\",\n",
    "    \"NS\": \"@StephenMcNeil\",\n",
    "    \"NU\": \"@JSavikataaq\",\n",
    "    \"ON\": \"@fordnation\",\n",
    "    \"PEI\": \"@dennyking\",\n",
    "    \"QC\": \"@francoislegault\",\n",
    "    \"SK\": \"@PremierScottMoe\",\n",
    "    \"YT\": \"@Premier_Silver\"\n",
    "}\n",
    "\n",
    "politicians = \" OR \".join([val for _,val in list(premier_dict.items())+list(edu_minister_dict.items())])\n",
    "\n",
    "politicians = f\"(({politicians}) ({covid_filters} {child_filters}))\"\n",
    "pol_query = create_query([politicians],country)\n",
    "from_date = \"2020-02-15\"\n",
    "to_date = \"2020-08-23\"\n",
    "print(pol_query,len(pol_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets,f_name = return_tweets(pol_query,from_date=from_date,to_date=to_date,max_pages=300,f_name=\"pol_mention\")\n",
    "f_name,len(tweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
